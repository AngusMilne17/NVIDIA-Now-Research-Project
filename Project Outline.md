# NVIDIA Now
The topic I have chosen is cloud gaming. Specifically, the NVIDIA streaming platform. The problem NVIDIA and all cloud-based game streaming 
platforms have is the heavy demand it has on the network and the need for low latency. Other streaming systems such as video platforms (e.g., Netflix) 
or audio platforms (e.g., Apple Music) do not require low latency and can easily buffer more content for a seamless experience.  However, cloud-based
game streaming introduces some challenges for a seamless real-time experience for the user which are not present in the other forms of streaming. 
Many techniques have already been employed to reduce the latency and network requirements. Compression, adaptive bitrate, adaptive framerate, adaptive 
resolution, and keyframes are all used by NVIDIA to try to reduce the amount of data being passed through the network. Although on the forefront of data 
rate optimization, the requirements for client internet connection and strain on network bandwidth are still obstacles that may cause problems for the average consumer.
Regarding the latency issue, NVIDIA has taken steps towards shortening the physical distance between the user and the NVIDIA system. By introducing data 
centers closer to populated areas, it shortens the time needed for the data to be sent to and from the game server which reduces the latency. Reducing 
input lag of controllers, applying low-latency networks, as well as monitoring the quality of the connections also play a role in reducing the latency 
to the required level.
NVIDIA uses NVIDIA reflex, predictive algorithms focused on optimizing the gaming experience rather than latency directly. The idea is to minimize the 
latency of the hardware and therefore reducing latency of the whole system. Implementing a concept by Google Stadia called negative latency, which has 
been compared to buffering in a video streaming service, can reduce the perceived latency by predicting the frames that will be needed by the user. This
could be a significant next step in reducing the latency of game streaming and would allow for greater flexibility in the hardware and network 
requirements while not affecting the quality of the user experience.
An exciting future aspect of cloud gaming is streaming VR content. As of now, the mentioned network and latency barriers don’t allow for quality streaming 
of VR. However, researchers are moving forward with a goal of eventually incorporating it into the cloud gaming libraries.

# Deadlines

October 10 - Continue research into compression, data transfer, and latency reducing mechanisms in the NVIDIA system. 

October 24 – Determine report structure and sections. Sketch the general idea for content of the sections.

November 7 – Evaluate and compare optimizations to other alternatives. Perhaps compression algorithm to others. Think of possible 
ways to gather and display relevant information: writing a small script or capturing traffic from some of the NVIDIA servers. 

November 21 – Write first draft and reevaluate areas that should be included or reworked.

December 5 – Continue research and continue any project needed for the report.

December 11 – Report due

